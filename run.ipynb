{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cowboy Bebop', 'Neon Genesis Evangelion: The End of Evangelion'] ---> ['Neon Genesis Evangelion'] 0.9805825242718446\n",
      "['Neon Genesis Evangelion: The End of Evangelion', 'Akira'] ---> ['Neon Genesis Evangelion'] 0.9784946236559139\n",
      "['Neon Genesis Evangelion: The End of Evangelion', 'Koukaku Kidoutai'] ---> ['Neon Genesis Evangelion'] 0.9771428571428571\n",
      "['Neon Genesis Evangelion: The End of Evangelion'] ---> ['Neon Genesis Evangelion'] 0.975609756097561\n",
      "['Naruto', 'Neon Genesis Evangelion: The End of Evangelion'] ---> ['Neon Genesis Evangelion'] 0.9748743718592966\n",
      "['Full Metal Panic! The Second Raid'] ---> ['Full Metal Panic!'] 0.9649122807017545\n",
      "['Full Metal Panic? Fumoffu', 'Full Metal Panic! The Second Raid'] ---> ['Full Metal Panic!'] 0.9627659574468085\n",
      "['Cowboy Bebop: Tengoku no Tobira'] ---> ['Cowboy Bebop'] 0.9411764705882353\n",
      "['Full Metal Panic? Fumoffu'] ---> ['Full Metal Panic!'] 0.8705882352941177\n",
      "['Full Metal Panic! The Second Raid'] ---> ['Full Metal Panic? Fumoffu'] 0.8245614035087719\n",
      "['Full Metal Panic!', 'Full Metal Panic! The Second Raid'] ---> ['Full Metal Panic? Fumoffu'] 0.8227272727272726\n",
      "['Full Metal Panic!', 'Full Metal Panic? Fumoffu'] ---> ['Full Metal Panic! The Second Raid'] 0.8153153153153152\n",
      "['Cowboy Bebop', 'One Piece'] ---> ['Naruto'] 0.8142857142857143\n",
      "['Cowboy Bebop', 'Akira'] ---> ['Neon Genesis Evangelion'] 0.8028169014084506\n"
     ]
    }
   ],
   "source": [
    "from agent import Agent\n",
    "agent = Agent(dataset_path='dataset', weight_path='weight', download_dataset=True, download_weight=True)\n",
    "agent.build_itemSetList(num_users=2000, num_animes=100) # max num_users=313670, num_animes=17172\n",
    "agent.build_apriori(minSup=0.1, minConf=0.8)\n",
    "# Get all rules of FP-growth algorithm by name\n",
    "for rule in agent.rules_apriori:\n",
    "    print(agent.anime_df.loc[agent.anime_df['MAL_ID'].isin(list(rule[0]))]['Name'].tolist(), end=' ')\n",
    "    print('--->', end=' ')\n",
    "    print(agent.anime_df.loc[agent.anime_df['MAL_ID'].isin(list(rule[1]))]['Name'].tolist(), end=' ')\n",
    "    print(rule[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hung\\Documents\\nam4\\ki_2\\Anime_project\\Anime_recommendations_system\\agent.py:61: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  sparse_df = pd.DataFrame.sparse.from_spmatrix(te_array, columns=te.columns_)\n",
      "c:\\Users\\hung\\Documents\\nam4\\ki_2\\Anime_project\\Anime_recommendations_system\\apriori_hash_tree.py:143: RuntimeWarning: divide by zero encountered in scalar remainder\n",
      "  return num % self.hash_num\n",
      "100%|██████████| 65/65 [00:00<00:00, 392.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cowboy Bebop', 'Neon Genesis Evangelion: The End of Evangelion'] ---> ['Neon Genesis Evangelion'] 0.9805825242718447\n",
      "['Neon Genesis Evangelion: The End of Evangelion', 'Akira'] ---> ['Neon Genesis Evangelion'] 0.978494623655914\n",
      "['Neon Genesis Evangelion: The End of Evangelion', 'Koukaku Kidoutai'] ---> ['Neon Genesis Evangelion'] 0.9771428571428571\n",
      "['Neon Genesis Evangelion: The End of Evangelion'] ---> ['Neon Genesis Evangelion'] 0.975609756097561\n",
      "['Naruto', 'Neon Genesis Evangelion: The End of Evangelion'] ---> ['Neon Genesis Evangelion'] 0.9748743718592965\n",
      "['Full Metal Panic! The Second Raid'] ---> ['Full Metal Panic!'] 0.9649122807017544\n",
      "['Full Metal Panic? Fumoffu', 'Full Metal Panic! The Second Raid'] ---> ['Full Metal Panic!'] 0.9627659574468085\n",
      "['Cowboy Bebop: Tengoku no Tobira'] ---> ['Cowboy Bebop'] 0.9411764705882353\n",
      "['Full Metal Panic? Fumoffu'] ---> ['Full Metal Panic!'] 0.8705882352941177\n",
      "['Full Metal Panic! The Second Raid'] ---> ['Full Metal Panic? Fumoffu'] 0.8245614035087719\n",
      "['Full Metal Panic!', 'Full Metal Panic! The Second Raid'] ---> ['Full Metal Panic? Fumoffu'] 0.8227272727272728\n",
      "['Full Metal Panic!', 'Full Metal Panic? Fumoffu'] ---> ['Full Metal Panic! The Second Raid'] 0.8153153153153153\n",
      "['Cowboy Bebop', 'One Piece'] ---> ['Naruto'] 0.8142857142857143\n",
      "['Cowboy Bebop', 'Akira'] ---> ['Neon Genesis Evangelion'] 0.8028169014084507\n"
     ]
    }
   ],
   "source": [
    "from agent import Agent\n",
    "agent = Agent(dataset_path='dataset', weight_path='weight', download_dataset=True, download_weight=True)\n",
    "agent.build_itemSetList(num_users=2000, num_animes=100) # max num_users=313670, num_animes=17172\n",
    "agent.build_apriori_hash_tree(minSup=0.1, minConf=0.8)\n",
    "# Get all rules of FP-growth algorithm by name\n",
    "for rule in agent.rules_apriori_hash_tree:\n",
    "    print(agent.anime_df.loc[agent.anime_df['MAL_ID'].isin(list(rule[0]))]['Name'].tolist(), end=' ')\n",
    "    print('--->', end=' ')\n",
    "    print(agent.anime_df.loc[agent.anime_df['MAL_ID'].isin(list(rule[1]))]['Name'].tolist(), end=' ')\n",
    "    print(rule[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1653/1653 [00:00<00:00, 598617.21it/s]\n",
      "100%|██████████| 1653/1653 [00:00<00:00, 35981.03it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 837.86it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3004.52it/s]\n",
      "100%|██████████| 3/3 [00:00<?, ?it/s]\n",
      "100%|██████████| 7/7 [00:00<?, ?it/s]\n",
      "100%|██████████| 7/7 [00:00<?, ?it/s]\n",
      "100%|██████████| 12/12 [00:00<?, ?it/s]\n",
      "100%|██████████| 12/12 [00:00<?, ?it/s]\n",
      "100%|██████████| 25/25 [00:00<?, ?it/s]\n",
      "100%|██████████| 25/25 [00:00<?, ?it/s]\n",
      "100%|██████████| 45/45 [00:00<?, ?it/s]\n",
      "100%|██████████| 45/45 [00:00<?, ?it/s]\n",
      "100%|██████████| 78/78 [00:00<?, ?it/s]\n",
      "100%|██████████| 78/78 [00:00<?, ?it/s]\n",
      "100%|██████████| 127/127 [00:00<?, ?it/s]\n",
      "100%|██████████| 127/127 [00:00<?, ?it/s]\n",
      "100%|██████████| 167/167 [00:00<?, ?it/s]\n",
      "100%|██████████| 167/167 [00:00<?, ?it/s]\n",
      "100%|██████████| 156/156 [00:00<?, ?it/s]\n",
      "100%|██████████| 156/156 [00:00<?, ?it/s]\n",
      "100%|██████████| 189/189 [00:00<?, ?it/s]\n",
      "100%|██████████| 189/189 [00:00<00:00, 189465.45it/s]\n",
      "100%|██████████| 174/174 [00:00<?, ?it/s]\n",
      "100%|██████████| 174/174 [00:00<?, ?it/s]\n",
      "100%|██████████| 196/196 [00:00<?, ?it/s]\n",
      "100%|██████████| 191/191 [00:00<?, ?it/s]\n",
      "100%|██████████| 193/193 [00:00<?, ?it/s]\n",
      "100%|██████████| 201/201 [00:00<?, ?it/s]\n",
      "100%|██████████| 204/204 [00:00<00:00, 243009.94it/s]\n",
      "100%|██████████| 204/204 [00:00<00:00, 201896.65it/s]\n",
      "100%|██████████| 195/195 [00:00<?, ?it/s]\n",
      "100%|██████████| 211/211 [00:00<00:00, 225592.19it/s]\n",
      "100%|██████████| 211/211 [00:00<00:00, 265924.92it/s]\n",
      "100%|██████████| 205/205 [00:00<00:00, 271754.84it/s]\n",
      "100%|██████████| 197/197 [00:00<00:00, 435341.35it/s]\n",
      "100%|██████████| 178/178 [00:00<00:00, 1773363.69it/s]\n",
      "100%|██████████| 169/169 [00:00<00:00, 338832.40it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1992.54it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 492.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 6452.78it/s]\n",
      "100%|██████████| 3/3 [00:00<?, ?it/s]\n",
      "100%|██████████| 7/7 [00:00<?, ?it/s]\n",
      "100%|██████████| 11/11 [00:00<?, ?it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 21959.71it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 3/3 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 3/3 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 490.39it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1370.69it/s]\n",
      "100%|██████████| 3/3 [00:00<?, ?it/s]\n",
      "100%|██████████| 7/7 [00:00<?, ?it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 10396.65it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 3/3 [00:00<?, ?it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3036.42it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2548.18it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 3/3 [00:00<?, ?it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3019.66it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 65/65 [00:00<00:00, 240.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cowboy Bebop', 'Neon Genesis Evangelion: The End of Evangelion'] ---> ['Neon Genesis Evangelion'] 0.9805825242718447\n",
      "['Neon Genesis Evangelion: The End of Evangelion', 'Akira'] ---> ['Neon Genesis Evangelion'] 0.978494623655914\n",
      "['Neon Genesis Evangelion: The End of Evangelion', 'Koukaku Kidoutai'] ---> ['Neon Genesis Evangelion'] 0.9771428571428571\n",
      "['Neon Genesis Evangelion: The End of Evangelion'] ---> ['Neon Genesis Evangelion'] 0.975609756097561\n",
      "['Naruto', 'Neon Genesis Evangelion: The End of Evangelion'] ---> ['Neon Genesis Evangelion'] 0.9748743718592965\n",
      "['Full Metal Panic! The Second Raid'] ---> ['Full Metal Panic!'] 0.9649122807017544\n",
      "['Full Metal Panic? Fumoffu', 'Full Metal Panic! The Second Raid'] ---> ['Full Metal Panic!'] 0.9627659574468085\n",
      "['Cowboy Bebop: Tengoku no Tobira'] ---> ['Cowboy Bebop'] 0.9411764705882353\n",
      "['Full Metal Panic? Fumoffu'] ---> ['Full Metal Panic!'] 0.8705882352941177\n",
      "['Full Metal Panic! The Second Raid'] ---> ['Full Metal Panic? Fumoffu'] 0.8245614035087719\n",
      "['Full Metal Panic!', 'Full Metal Panic! The Second Raid'] ---> ['Full Metal Panic? Fumoffu'] 0.8227272727272728\n",
      "['Full Metal Panic!', 'Full Metal Panic? Fumoffu'] ---> ['Full Metal Panic! The Second Raid'] 0.8153153153153153\n",
      "['Cowboy Bebop', 'One Piece'] ---> ['Naruto'] 0.8142857142857143\n",
      "['Cowboy Bebop', 'Akira'] ---> ['Neon Genesis Evangelion'] 0.8028169014084507\n"
     ]
    }
   ],
   "source": [
    "from agent import Agent\n",
    "agent = Agent(dataset_path='dataset', weight_path='weight', download_dataset=True, download_weight=True)\n",
    "agent.build_itemSetList(num_users=2000, num_animes=100) # max num_users=313670, num_animes=17172\n",
    "agent.build_fpgrowth(minSup=0.1, minConf=0.8)\n",
    "# Get all rules of FP-growth algorithm by name\n",
    "for rule in agent.rules_fpgrowth:\n",
    "    print(agent.anime_df.loc[agent.anime_df['MAL_ID'].isin(list(rule[0]))]['Name'].tolist(), end=' ')\n",
    "    print('--->', end=' ')\n",
    "    print(agent.anime_df.loc[agent.anime_df['MAL_ID'].isin(list(rule[1]))]['Name'].tolist(), end=' ')\n",
    "    print(rule[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('M',), 0.6)\n",
      "(('O',), 0.6)\n",
      "(('K',), 1.0)\n",
      "(('E',), 0.8)\n",
      "(('Y',), 0.6)\n",
      "(('M', 'K'), 0.6)\n",
      "(('K', 'O'), 0.6)\n",
      "(('K', 'Y'), 0.6)\n",
      "(('E', 'O'), 0.6)\n",
      "(('E', 'K'), 0.8)\n",
      "(('E', 'K', 'O'), 0.6)\n",
      "[{'M'}, {'K'}, 1.0]\n",
      "[{'O'}, {'K'}, 1.0]\n",
      "[{'Y'}, {'K'}, 1.0]\n",
      "[{'O'}, {'E'}, 1.0]\n",
      "[{'E'}, {'K'}, 1.0]\n",
      "[{'O'}, {'E', 'K'}, 1.0]\n",
      "[{'E', 'O'}, {'K'}, 1.0]\n",
      "[{'K', 'O'}, {'E'}, 1.0]\n",
      "[{'K'}, {'E'}, 0.8]\n"
     ]
    }
   ],
   "source": [
    "from agent import Agent\n",
    "agent = Agent(custom_dataset=True)\n",
    "agent.itemSetList = [\n",
    "        ['M', 'O', 'N', 'K', 'E', 'Y'],\n",
    "        ['D', 'O', 'N', 'K', 'E', 'Y'],\n",
    "        ['M', 'A', 'K', 'E'],\n",
    "        ['M', 'U', 'C', 'K', 'Y'],\n",
    "        ['C', 'O', 'O', 'K', 'I', 'E']\n",
    "    ]\n",
    "agent.build_apriori(minSup=0.6, minConf=0.8)\n",
    "for i in agent.freqItemSet_apriori:\n",
    "    print(i)\n",
    "for i in agent.rules_apriori:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hung\\Documents\\nam4\\ki_2\\Anime_project\\Anime_recommendations_system\\agent.py:61: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  sparse_df = pd.DataFrame.sparse.from_spmatrix(te_array, columns=te.columns_)\n",
      "c:\\Users\\hung\\Documents\\nam4\\ki_2\\Anime_project\\Anime_recommendations_system\\apriori_hash_tree.py:143: RuntimeWarning: divide by zero encountered in scalar remainder\n",
      "  return num % self.hash_num\n",
      "100%|██████████| 11/11 [00:00<00:00, 4979.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'E'}\n",
      "{'K'}\n",
      "{'M'}\n",
      "{'O'}\n",
      "{'Y'}\n",
      "{'E', 'K'}\n",
      "{'E', 'O'}\n",
      "{'M', 'K'}\n",
      "{'K', 'O'}\n",
      "{'K', 'Y'}\n",
      "{'E', 'K', 'O'}\n",
      "[{'E'}, {'K'}, 1.0]\n",
      "[{'O'}, {'E'}, 1.0]\n",
      "[{'M'}, {'K'}, 1.0]\n",
      "[{'O'}, {'K'}, 1.0]\n",
      "[{'Y'}, {'K'}, 1.0]\n",
      "[{'O'}, {'E', 'K'}, 1.0]\n",
      "[{'E', 'O'}, {'K'}, 1.0]\n",
      "[{'K', 'O'}, {'E'}, 1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from agent import Agent\n",
    "agent = Agent(custom_dataset=True)\n",
    "agent.itemSetList = [\n",
    "        ['M', 'O', 'N', 'K', 'E', 'Y'],\n",
    "        ['D', 'O', 'N', 'K', 'E', 'Y'],\n",
    "        ['M', 'A', 'K', 'E'],\n",
    "        ['M', 'U', 'C', 'K', 'Y'],\n",
    "        ['C', 'O', 'O', 'K', 'I', 'E']\n",
    "    ]\n",
    "agent.build_apriori_hash_tree(minSup=0.6, minConf=0.8)\n",
    "for i in agent.freqItemSet_apriori_hash_tree:\n",
    "    print(i)\n",
    "for i in agent.rules_apriori_hash_tree:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E \n",
      "K \n",
      "M \n",
      "O \n",
      "Y \n",
      "E K \n",
      "E O \n",
      "M K \n",
      "K O \n",
      "K Y \n",
      "E K O \n"
     ]
    }
   ],
   "source": [
    "for i in agent.freqItemSet_apriori_hash_tree:\n",
    "    for j in i:\n",
    "        print(j, end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 8432.46it/s]\n",
      "100%|██████████| 5/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null\n",
      "└── K [count=5]\n",
      "    ├── O [count=4]\n",
      "    │   └── E [count=3]\n",
      "    │       ├── M [count=1]\n",
      "    │       │   └── Y [count=1]\n",
      "    │       └── Y [count=1]\n",
      "    ├── E [count=1]\n",
      "    │   └── M [count=1]\n",
      "    └── M [count=1]\n",
      "        └── Y [count=1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1608.55it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 6000.43it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2304.56it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2490.68it/s]\n",
      "100%|██████████| 3/3 [00:00<?, ?it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2962.78it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1120.77it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1793.97it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 26214.40it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 294.88it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 4227.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'K'}\n",
      "{'O'}\n",
      "{'E'}\n",
      "{'M'}\n",
      "{'Y'}\n",
      "{'K', 'Y'}\n",
      "{'M', 'K'}\n",
      "{'E', 'O'}\n",
      "{'E', 'K'}\n",
      "{'E', 'K', 'O'}\n",
      "{'K', 'O'}\n",
      "[{'Y'}, {'K'}, 1.0]\n",
      "[{'M'}, {'K'}, 1.0]\n",
      "[{'O'}, {'E'}, 1.0]\n",
      "[{'E'}, {'K'}, 1.0]\n",
      "[{'O'}, {'E', 'K'}, 1.0]\n",
      "[{'E', 'O'}, {'K'}, 1.0]\n",
      "[{'K', 'O'}, {'E'}, 1.0]\n",
      "[{'O'}, {'K'}, 1.0]\n",
      "[{'K'}, {'E'}, 0.8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from agent import Agent\n",
    "agent = Agent(custom_dataset=True)\n",
    "agent.itemSetList = [\n",
    "        ['M', 'O', 'N', 'K', 'E', 'Y'],\n",
    "        ['D', 'O', 'N', 'K', 'E', 'Y'],\n",
    "        ['M', 'A', 'K', 'E'],\n",
    "        ['M', 'U', 'C', 'K', 'Y'],\n",
    "        ['C', 'O', 'O', 'K', 'I', 'E']\n",
    "    ]\n",
    "agent.build_fpgrowth(visualize = True,minSup=0.6, minConf=0.79)\n",
    "for i in agent.freqItemSet_fpgrowth:\n",
    "    print(i)\n",
    "for i in agent.rules_fpgrowth:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Dữ liệu mẫu: danh sách các giỏ hàng\n",
    "dataset = [\n",
    "    ['M', 'O', 'N', 'K', 'E', 'Y'],\n",
    "    ['D', 'O', 'N', 'K', 'E', 'Y'],\n",
    "    ['M', 'A', 'K', 'E'],\n",
    "    ['M', 'U', 'C', 'K', 'Y'],\n",
    "    ['C', 'O', 'O', 'K', 'I', 'E']\n",
    "]\n",
    "\n",
    "\n",
    "# Chuyển đổi dữ liệu thành dạng one-hot encoding\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(dataset).transform(dataset)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Áp dụng thuật toán FP-Growth\n",
    "frequent_itemsets = fpgrowth(df, min_support=0.6, use_colnames=True)\n",
    "\n",
    "print(frequent_itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent import Agent\n",
    "agent = Agent(dataset_path='dataset', weight_path='weight', download_dataset=True, download_weight=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245                                                 Bleach\n",
      "451                                Yu☆Gi☆Oh! Duel Monsters\n",
      "515                                              Yu☆Gi☆Oh!\n",
      "1533                    Bleach Movie 1: Memories of Nobody\n",
      "2330                               Robin Hood no Daibouken\n",
      "2593                                 Cinderella Monogatari\n",
      "2645     Bleach Movie 2: The DiamondDust Rebellion - Mo...\n",
      "2745                                        Kaiketsu Zorro\n",
      "3293                            Shirayuki Hime no Densetsu\n",
      "3316                                          Meiken Jolie\n",
      "3489                                    Muka Muka Paradise\n",
      "3728                                            Topo Gigio\n",
      "3745                                   Yumemiru Topo Gigio\n",
      "3762                                         Tekken Chinmi\n",
      "3850     Bleach Movie 3: Fade to Black - Kimi no Na wo ...\n",
      "4836     Yu☆Gi☆Oh! Movie: Chou Yuugou! Toki wo Koeta Ki...\n",
      "8965                                       Gaki Deka (OVA)\n",
      "9862                              Boruto: Naruto the Movie\n",
      "15485                          Peter-kun no Hinotama Taiji\n",
      "Name: Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(agent.find_anime_for_user_using_episode(id=0, top_k=5, num_animes=4, return_name=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
